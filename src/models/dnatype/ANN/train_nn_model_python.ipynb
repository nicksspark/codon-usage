{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import keras.metrics as metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.000e+00, 1.654e-02, 1.203e-02, ..., 2.510e-03, 5.000e-04,\n",
       "        0.000e+00],\n",
       "       [0.000e+00, 2.714e-02, 1.357e-02, ..., 2.710e-03, 6.800e-04,\n",
       "        0.000e+00],\n",
       "       [0.000e+00, 1.974e-02, 2.180e-02, ..., 3.910e-03, 0.000e+00,\n",
       "        1.440e-03],\n",
       "       ...,\n",
       "       [1.000e+00, 1.423e-02, 3.321e-02, ..., 3.560e-03, 1.190e-03,\n",
       "        2.017e-02],\n",
       "       [0.000e+00, 1.757e-02, 2.028e-02, ..., 9.900e-04, 7.900e-04,\n",
       "        1.560e-03],\n",
       "       [1.000e+00, 1.778e-02, 3.724e-02, ..., 1.560e-03, 1.140e-03,\n",
       "        2.161e-02]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset \n",
    "\n",
    "full_dataset = pd.read_csv(\"/Users/nickpark/Desktop/codon-data/codon_usage.csv\", low_memory=False)\n",
    "dataset = full_dataset[full_dataset[\"DNAtype\"].eq(0) | full_dataset[\"DNAtype\"].eq(1) | full_dataset[\"DNAtype\"].eq(2)]\n",
    "\n",
    "# Remove irrelevant columns\n",
    "\n",
    "dataset = dataset.drop([\"Kingdom\", \"SpeciesID\", \"Ncodons\", \"SpeciesName\"], axis=1)\n",
    "\n",
    "# Remove weird rows\n",
    "\n",
    "dataset = dataset.apply(pd.to_numeric, errors='coerce')\n",
    "dataset = dataset[~dataset.applymap(np.isnan).any(1)]\n",
    "dataset = dataset.to_numpy(dtype='float64')\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12980, 64)\n",
      "(12980,)\n"
     ]
    }
   ],
   "source": [
    "X = dataset[:,1:]\n",
    "y = dataset[:,0].astype('int')\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-class classification with Keras\n",
    "\n",
    "# Encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "\n",
    "# Convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "# Define baseline model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(15, input_dim=64, activation='relu'))\n",
    "\tmodel.add(Dense(3, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=100, batch_size=5, verbose=2)\n",
    "kfold = KFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2337/2337 - 3s - loss: 0.3581 - accuracy: 0.8850\n",
      "Epoch 2/100\n",
      "2337/2337 - 2s - loss: 0.1271 - accuracy: 0.9548\n",
      "Epoch 3/100\n",
      "2337/2337 - 2s - loss: 0.0823 - accuracy: 0.9745\n",
      "Epoch 4/100\n",
      "2337/2337 - 2s - loss: 0.0608 - accuracy: 0.9811\n",
      "Epoch 5/100\n",
      "2337/2337 - 2s - loss: 0.0488 - accuracy: 0.9862\n",
      "Epoch 6/100\n",
      "2337/2337 - 2s - loss: 0.0415 - accuracy: 0.9884\n",
      "Epoch 7/100\n",
      "2337/2337 - 2s - loss: 0.0370 - accuracy: 0.9888\n",
      "Epoch 8/100\n",
      "2337/2337 - 2s - loss: 0.0343 - accuracy: 0.9896\n",
      "Epoch 9/100\n",
      "2337/2337 - 2s - loss: 0.0322 - accuracy: 0.9902\n",
      "Epoch 10/100\n",
      "2337/2337 - 2s - loss: 0.0310 - accuracy: 0.9905\n",
      "Epoch 11/100\n",
      "2337/2337 - 2s - loss: 0.0290 - accuracy: 0.9915\n",
      "Epoch 12/100\n",
      "2337/2337 - 2s - loss: 0.0283 - accuracy: 0.9913\n",
      "Epoch 13/100\n",
      "2337/2337 - 2s - loss: 0.0274 - accuracy: 0.9921\n",
      "Epoch 14/100\n",
      "2337/2337 - 2s - loss: 0.0265 - accuracy: 0.9920\n",
      "Epoch 15/100\n",
      "2337/2337 - 2s - loss: 0.0259 - accuracy: 0.9927\n",
      "Epoch 16/100\n",
      "2337/2337 - 2s - loss: 0.0251 - accuracy: 0.9934\n",
      "Epoch 17/100\n",
      "2337/2337 - 2s - loss: 0.0246 - accuracy: 0.9933\n",
      "Epoch 18/100\n",
      "2337/2337 - 2s - loss: 0.0244 - accuracy: 0.9930\n",
      "Epoch 19/100\n",
      "2337/2337 - 2s - loss: 0.0238 - accuracy: 0.9935\n",
      "Epoch 20/100\n",
      "2337/2337 - 2s - loss: 0.0234 - accuracy: 0.9934\n",
      "Epoch 21/100\n",
      "2337/2337 - 2s - loss: 0.0231 - accuracy: 0.9939\n",
      "Epoch 22/100\n",
      "2337/2337 - 2s - loss: 0.0225 - accuracy: 0.9935\n",
      "Epoch 23/100\n",
      "2337/2337 - 2s - loss: 0.0222 - accuracy: 0.9938\n",
      "Epoch 24/100\n",
      "2337/2337 - 2s - loss: 0.0217 - accuracy: 0.9938\n",
      "Epoch 25/100\n",
      "2337/2337 - 2s - loss: 0.0216 - accuracy: 0.9940\n",
      "Epoch 26/100\n",
      "2337/2337 - 2s - loss: 0.0214 - accuracy: 0.9940\n",
      "Epoch 27/100\n",
      "2337/2337 - 2s - loss: 0.0207 - accuracy: 0.9941\n",
      "Epoch 28/100\n",
      "2337/2337 - 2s - loss: 0.0206 - accuracy: 0.9944\n",
      "Epoch 29/100\n",
      "2337/2337 - 2s - loss: 0.0204 - accuracy: 0.9944\n",
      "Epoch 30/100\n",
      "2337/2337 - 2s - loss: 0.0200 - accuracy: 0.9939\n",
      "Epoch 31/100\n",
      "2337/2337 - 2s - loss: 0.0200 - accuracy: 0.9940\n",
      "Epoch 32/100\n",
      "2337/2337 - 2s - loss: 0.0197 - accuracy: 0.9949\n",
      "Epoch 33/100\n",
      "2337/2337 - 2s - loss: 0.0193 - accuracy: 0.9942\n",
      "Epoch 34/100\n",
      "2337/2337 - 2s - loss: 0.0190 - accuracy: 0.9947\n",
      "Epoch 35/100\n",
      "2337/2337 - 2s - loss: 0.0190 - accuracy: 0.9944\n",
      "Epoch 36/100\n",
      "2337/2337 - 2s - loss: 0.0190 - accuracy: 0.9947\n",
      "Epoch 37/100\n",
      "2337/2337 - 2s - loss: 0.0186 - accuracy: 0.9944\n",
      "Epoch 38/100\n",
      "2337/2337 - 2s - loss: 0.0183 - accuracy: 0.9950\n",
      "Epoch 39/100\n",
      "2337/2337 - 2s - loss: 0.0180 - accuracy: 0.9949\n",
      "Epoch 40/100\n",
      "2337/2337 - 2s - loss: 0.0181 - accuracy: 0.9950\n",
      "Epoch 41/100\n",
      "2337/2337 - 2s - loss: 0.0182 - accuracy: 0.9947\n",
      "Epoch 42/100\n",
      "2337/2337 - 2s - loss: 0.0177 - accuracy: 0.9949\n",
      "Epoch 43/100\n",
      "2337/2337 - 2s - loss: 0.0173 - accuracy: 0.9954\n",
      "Epoch 44/100\n",
      "2337/2337 - 2s - loss: 0.0172 - accuracy: 0.9952\n",
      "Epoch 45/100\n",
      "2337/2337 - 2s - loss: 0.0168 - accuracy: 0.9946\n",
      "Epoch 46/100\n",
      "2337/2337 - 2s - loss: 0.0170 - accuracy: 0.9952\n",
      "Epoch 47/100\n",
      "2337/2337 - 2s - loss: 0.0170 - accuracy: 0.9949\n",
      "Epoch 48/100\n",
      "2337/2337 - 2s - loss: 0.0166 - accuracy: 0.9953\n",
      "Epoch 49/100\n",
      "2337/2337 - 2s - loss: 0.0166 - accuracy: 0.9950\n",
      "Epoch 50/100\n",
      "2337/2337 - 2s - loss: 0.0163 - accuracy: 0.9955\n",
      "Epoch 51/100\n",
      "2337/2337 - 3s - loss: 0.0161 - accuracy: 0.9957\n",
      "Epoch 52/100\n",
      "2337/2337 - 2s - loss: 0.0159 - accuracy: 0.9955\n",
      "Epoch 53/100\n",
      "2337/2337 - 2s - loss: 0.0158 - accuracy: 0.9953\n",
      "Epoch 54/100\n",
      "2337/2337 - 3s - loss: 0.0157 - accuracy: 0.9954\n",
      "Epoch 55/100\n",
      "2337/2337 - 2s - loss: 0.0155 - accuracy: 0.9961\n",
      "Epoch 56/100\n",
      "2337/2337 - 2s - loss: 0.0158 - accuracy: 0.9952\n",
      "Epoch 57/100\n",
      "2337/2337 - 2s - loss: 0.0155 - accuracy: 0.9957\n",
      "Epoch 58/100\n",
      "2337/2337 - 2s - loss: 0.0153 - accuracy: 0.9955\n",
      "Epoch 59/100\n",
      "2337/2337 - 2s - loss: 0.0152 - accuracy: 0.9958\n",
      "Epoch 60/100\n",
      "2337/2337 - 4s - loss: 0.0151 - accuracy: 0.9957\n",
      "Epoch 61/100\n",
      "2337/2337 - 2s - loss: 0.0148 - accuracy: 0.9960\n",
      "Epoch 62/100\n",
      "2337/2337 - 2s - loss: 0.0150 - accuracy: 0.9960\n",
      "Epoch 63/100\n",
      "2337/2337 - 2s - loss: 0.0149 - accuracy: 0.9960\n",
      "Epoch 64/100\n",
      "2337/2337 - 2s - loss: 0.0148 - accuracy: 0.9957\n",
      "Epoch 65/100\n",
      "2337/2337 - 2s - loss: 0.0145 - accuracy: 0.9958\n",
      "Epoch 66/100\n",
      "2337/2337 - 2s - loss: 0.0144 - accuracy: 0.9958\n",
      "Epoch 67/100\n",
      "2337/2337 - 2s - loss: 0.0146 - accuracy: 0.9956\n",
      "Epoch 68/100\n",
      "2337/2337 - 2s - loss: 0.0136 - accuracy: 0.9961\n",
      "Epoch 69/100\n",
      "2337/2337 - 2s - loss: 0.0141 - accuracy: 0.9955\n",
      "Epoch 70/100\n",
      "2337/2337 - 2s - loss: 0.0140 - accuracy: 0.9957\n",
      "Epoch 71/100\n",
      "2337/2337 - 3s - loss: 0.0137 - accuracy: 0.9965\n",
      "Epoch 72/100\n",
      "2337/2337 - 4s - loss: 0.0137 - accuracy: 0.9961\n",
      "Epoch 73/100\n",
      "2337/2337 - 3s - loss: 0.0142 - accuracy: 0.9961\n",
      "Epoch 74/100\n",
      "2337/2337 - 3s - loss: 0.0135 - accuracy: 0.9964\n",
      "Epoch 75/100\n",
      "2337/2337 - 2s - loss: 0.0137 - accuracy: 0.9961\n",
      "Epoch 76/100\n",
      "2337/2337 - 2s - loss: 0.0135 - accuracy: 0.9960\n",
      "Epoch 77/100\n",
      "2337/2337 - 3s - loss: 0.0137 - accuracy: 0.9961\n",
      "Epoch 78/100\n",
      "2337/2337 - 2s - loss: 0.0136 - accuracy: 0.9962\n",
      "Epoch 79/100\n",
      "2337/2337 - 2s - loss: 0.0133 - accuracy: 0.9963\n",
      "Epoch 80/100\n",
      "2337/2337 - 2s - loss: 0.0133 - accuracy: 0.9957\n",
      "Epoch 81/100\n",
      "2337/2337 - 3s - loss: 0.0133 - accuracy: 0.9962\n",
      "Epoch 82/100\n",
      "2337/2337 - 2s - loss: 0.0128 - accuracy: 0.9964\n",
      "Epoch 83/100\n",
      "2337/2337 - 2s - loss: 0.0133 - accuracy: 0.9960\n",
      "Epoch 84/100\n",
      "2337/2337 - 2s - loss: 0.0129 - accuracy: 0.9960\n",
      "Epoch 85/100\n",
      "2337/2337 - 2s - loss: 0.0129 - accuracy: 0.9961\n",
      "Epoch 86/100\n",
      "2337/2337 - 2s - loss: 0.0128 - accuracy: 0.9959\n",
      "Epoch 87/100\n",
      "2337/2337 - 3s - loss: 0.0126 - accuracy: 0.9963\n",
      "Epoch 88/100\n",
      "2337/2337 - 3s - loss: 0.0127 - accuracy: 0.9965\n",
      "Epoch 89/100\n",
      "2337/2337 - 2s - loss: 0.0128 - accuracy: 0.9963\n",
      "Epoch 90/100\n",
      "2337/2337 - 2s - loss: 0.0124 - accuracy: 0.9961\n",
      "Epoch 91/100\n",
      "2337/2337 - 2s - loss: 0.0128 - accuracy: 0.9966\n",
      "Epoch 92/100\n",
      "2337/2337 - 2s - loss: 0.0124 - accuracy: 0.9963\n",
      "Epoch 93/100\n",
      "2337/2337 - 2s - loss: 0.0125 - accuracy: 0.9964\n",
      "Epoch 94/100\n",
      "2337/2337 - 2s - loss: 0.0123 - accuracy: 0.9962\n",
      "Epoch 95/100\n",
      "2337/2337 - 2s - loss: 0.0121 - accuracy: 0.9964\n",
      "Epoch 96/100\n",
      "2337/2337 - 2s - loss: 0.0121 - accuracy: 0.9966\n",
      "Epoch 97/100\n",
      "2337/2337 - 2s - loss: 0.0121 - accuracy: 0.9966\n",
      "Epoch 98/100\n",
      "2337/2337 - 2s - loss: 0.0120 - accuracy: 0.9961\n",
      "Epoch 99/100\n",
      "2337/2337 - 3s - loss: 0.0122 - accuracy: 0.9965\n",
      "Epoch 100/100\n",
      "2337/2337 - 2s - loss: 0.0123 - accuracy: 0.9967\n",
      "260/260 - 0s - loss: 0.0143 - accuracy: 0.9938\n",
      "Epoch 1/100\n",
      "2337/2337 - 2s - loss: 0.4046 - accuracy: 0.8659\n",
      "Epoch 2/100\n",
      "2337/2337 - 2s - loss: 0.1477 - accuracy: 0.9450\n",
      "Epoch 3/100\n",
      "2337/2337 - 3s - loss: 0.0940 - accuracy: 0.9715\n",
      "Epoch 4/100\n",
      "2337/2337 - 2s - loss: 0.0682 - accuracy: 0.9797\n",
      "Epoch 5/100\n",
      "2337/2337 - 2s - loss: 0.0543 - accuracy: 0.9840\n",
      "Epoch 6/100\n",
      "2337/2337 - 2s - loss: 0.0458 - accuracy: 0.9869\n",
      "Epoch 7/100\n",
      "2337/2337 - 2s - loss: 0.0406 - accuracy: 0.9883\n",
      "Epoch 8/100\n",
      "2337/2337 - 2s - loss: 0.0369 - accuracy: 0.9884\n",
      "Epoch 9/100\n",
      "2337/2337 - 2s - loss: 0.0345 - accuracy: 0.9891\n",
      "Epoch 10/100\n",
      "2337/2337 - 2s - loss: 0.0325 - accuracy: 0.9897\n",
      "Epoch 11/100\n",
      "2337/2337 - 2s - loss: 0.0311 - accuracy: 0.9904\n",
      "Epoch 12/100\n",
      "2337/2337 - 2s - loss: 0.0298 - accuracy: 0.9908\n",
      "Epoch 13/100\n",
      "2337/2337 - 2s - loss: 0.0286 - accuracy: 0.9910\n",
      "Epoch 14/100\n",
      "2337/2337 - 2s - loss: 0.0278 - accuracy: 0.9919\n",
      "Epoch 15/100\n",
      "2337/2337 - 2s - loss: 0.0270 - accuracy: 0.9920\n",
      "Epoch 16/100\n",
      "2337/2337 - 2s - loss: 0.0265 - accuracy: 0.9914\n",
      "Epoch 17/100\n",
      "2337/2337 - 2s - loss: 0.0256 - accuracy: 0.9925\n",
      "Epoch 18/100\n",
      "2337/2337 - 2s - loss: 0.0252 - accuracy: 0.9918\n",
      "Epoch 19/100\n",
      "2337/2337 - 2s - loss: 0.0245 - accuracy: 0.9920\n",
      "Epoch 20/100\n",
      "2337/2337 - 2s - loss: 0.0240 - accuracy: 0.9924\n",
      "Epoch 21/100\n",
      "2337/2337 - 2s - loss: 0.0238 - accuracy: 0.9926\n",
      "Epoch 22/100\n",
      "2337/2337 - 2s - loss: 0.0234 - accuracy: 0.9926\n",
      "Epoch 23/100\n",
      "2337/2337 - 2s - loss: 0.0228 - accuracy: 0.9934\n",
      "Epoch 24/100\n",
      "2337/2337 - 2s - loss: 0.0222 - accuracy: 0.9934\n",
      "Epoch 25/100\n",
      "2337/2337 - 2s - loss: 0.0220 - accuracy: 0.9935\n",
      "Epoch 26/100\n",
      "2337/2337 - 2s - loss: 0.0216 - accuracy: 0.9933\n",
      "Epoch 27/100\n",
      "2337/2337 - 2s - loss: 0.0216 - accuracy: 0.9932\n",
      "Epoch 28/100\n",
      "2337/2337 - 2s - loss: 0.0210 - accuracy: 0.9936\n",
      "Epoch 29/100\n",
      "2337/2337 - 2s - loss: 0.0209 - accuracy: 0.9937\n",
      "Epoch 30/100\n",
      "2337/2337 - 2s - loss: 0.0200 - accuracy: 0.9947\n",
      "Epoch 31/100\n",
      "2337/2337 - 2s - loss: 0.0200 - accuracy: 0.9940\n",
      "Epoch 32/100\n",
      "2337/2337 - 2s - loss: 0.0199 - accuracy: 0.9941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "2337/2337 - 2s - loss: 0.0197 - accuracy: 0.9940\n",
      "Epoch 34/100\n",
      "2337/2337 - 2s - loss: 0.0196 - accuracy: 0.9942\n",
      "Epoch 35/100\n",
      "2337/2337 - 2s - loss: 0.0188 - accuracy: 0.9946\n",
      "Epoch 36/100\n",
      "2337/2337 - 2s - loss: 0.0189 - accuracy: 0.9948\n",
      "Epoch 37/100\n",
      "2337/2337 - 2s - loss: 0.0189 - accuracy: 0.9944\n",
      "Epoch 38/100\n",
      "2337/2337 - 2s - loss: 0.0187 - accuracy: 0.9945\n",
      "Epoch 39/100\n",
      "2337/2337 - 2s - loss: 0.0183 - accuracy: 0.9946\n",
      "Epoch 40/100\n",
      "2337/2337 - 2s - loss: 0.0180 - accuracy: 0.9953\n",
      "Epoch 41/100\n",
      "2337/2337 - 2s - loss: 0.0176 - accuracy: 0.9947\n",
      "Epoch 42/100\n",
      "2337/2337 - 2s - loss: 0.0176 - accuracy: 0.9948\n",
      "Epoch 43/100\n",
      "2337/2337 - 2s - loss: 0.0177 - accuracy: 0.9949\n",
      "Epoch 44/100\n",
      "2337/2337 - 2s - loss: 0.0175 - accuracy: 0.9949\n",
      "Epoch 45/100\n",
      "2337/2337 - 2s - loss: 0.0167 - accuracy: 0.9954\n",
      "Epoch 46/100\n",
      "2337/2337 - 2s - loss: 0.0170 - accuracy: 0.9950\n",
      "Epoch 47/100\n",
      "2337/2337 - 2s - loss: 0.0167 - accuracy: 0.9953\n",
      "Epoch 48/100\n",
      "2337/2337 - 2s - loss: 0.0166 - accuracy: 0.9949\n",
      "Epoch 49/100\n",
      "2337/2337 - 2s - loss: 0.0159 - accuracy: 0.9954\n",
      "Epoch 50/100\n",
      "2337/2337 - 2s - loss: 0.0159 - accuracy: 0.9954\n",
      "Epoch 51/100\n",
      "2337/2337 - 2s - loss: 0.0161 - accuracy: 0.9954\n",
      "Epoch 52/100\n",
      "2337/2337 - 2s - loss: 0.0158 - accuracy: 0.9954\n",
      "Epoch 53/100\n",
      "2337/2337 - 2s - loss: 0.0156 - accuracy: 0.9958\n",
      "Epoch 54/100\n",
      "2337/2337 - 2s - loss: 0.0156 - accuracy: 0.9949\n",
      "Epoch 55/100\n",
      "2337/2337 - 2s - loss: 0.0155 - accuracy: 0.9954\n",
      "Epoch 56/100\n",
      "2337/2337 - 2s - loss: 0.0153 - accuracy: 0.9955\n",
      "Epoch 57/100\n",
      "2337/2337 - 2s - loss: 0.0154 - accuracy: 0.9954\n",
      "Epoch 58/100\n",
      "2337/2337 - 2s - loss: 0.0152 - accuracy: 0.9955\n",
      "Epoch 59/100\n",
      "2337/2337 - 2s - loss: 0.0149 - accuracy: 0.9955\n",
      "Epoch 60/100\n",
      "2337/2337 - 2s - loss: 0.0149 - accuracy: 0.9953\n",
      "Epoch 61/100\n",
      "2337/2337 - 2s - loss: 0.0147 - accuracy: 0.9960\n",
      "Epoch 62/100\n",
      "2337/2337 - 2s - loss: 0.0144 - accuracy: 0.9956\n",
      "Epoch 63/100\n",
      "2337/2337 - 2s - loss: 0.0143 - accuracy: 0.9959\n",
      "Epoch 64/100\n",
      "2337/2337 - 2s - loss: 0.0143 - accuracy: 0.9957\n",
      "Epoch 65/100\n",
      "2337/2337 - 2s - loss: 0.0145 - accuracy: 0.9960\n",
      "Epoch 66/100\n",
      "2337/2337 - 2s - loss: 0.0144 - accuracy: 0.9957\n",
      "Epoch 67/100\n",
      "2337/2337 - 2s - loss: 0.0142 - accuracy: 0.9958\n",
      "Epoch 68/100\n",
      "2337/2337 - 2s - loss: 0.0141 - accuracy: 0.9960\n",
      "Epoch 69/100\n",
      "2337/2337 - 3s - loss: 0.0141 - accuracy: 0.9957\n",
      "Epoch 70/100\n",
      "2337/2337 - 2s - loss: 0.0135 - accuracy: 0.9961\n",
      "Epoch 71/100\n",
      "2337/2337 - 2s - loss: 0.0132 - accuracy: 0.9959\n",
      "Epoch 72/100\n",
      "2337/2337 - 2s - loss: 0.0138 - accuracy: 0.9957\n",
      "Epoch 73/100\n",
      "2337/2337 - 2s - loss: 0.0134 - accuracy: 0.9962\n",
      "Epoch 74/100\n",
      "2337/2337 - 2s - loss: 0.0133 - accuracy: 0.9955\n",
      "Epoch 75/100\n",
      "2337/2337 - 2s - loss: 0.0135 - accuracy: 0.9959\n",
      "Epoch 76/100\n",
      "2337/2337 - 2s - loss: 0.0132 - accuracy: 0.9963\n",
      "Epoch 77/100\n",
      "2337/2337 - 2s - loss: 0.0131 - accuracy: 0.9961\n",
      "Epoch 78/100\n",
      "2337/2337 - 2s - loss: 0.0130 - accuracy: 0.9960\n",
      "Epoch 79/100\n",
      "2337/2337 - 2s - loss: 0.0129 - accuracy: 0.9958\n",
      "Epoch 80/100\n",
      "2337/2337 - 2s - loss: 0.0131 - accuracy: 0.9962\n",
      "Epoch 81/100\n",
      "2337/2337 - 2s - loss: 0.0128 - accuracy: 0.9962\n",
      "Epoch 82/100\n",
      "2337/2337 - 2s - loss: 0.0127 - accuracy: 0.9967\n",
      "Epoch 83/100\n",
      "2337/2337 - 2s - loss: 0.0124 - accuracy: 0.9964\n",
      "Epoch 84/100\n",
      "2337/2337 - 2s - loss: 0.0124 - accuracy: 0.9961\n",
      "Epoch 85/100\n",
      "2337/2337 - 2s - loss: 0.0125 - accuracy: 0.9959\n",
      "Epoch 86/100\n",
      "2337/2337 - 2s - loss: 0.0123 - accuracy: 0.9962\n",
      "Epoch 87/100\n",
      "2337/2337 - 2s - loss: 0.0119 - accuracy: 0.9967\n",
      "Epoch 88/100\n",
      "2337/2337 - 2s - loss: 0.0124 - accuracy: 0.9960\n",
      "Epoch 89/100\n",
      "2337/2337 - 2s - loss: 0.0121 - accuracy: 0.9963\n",
      "Epoch 90/100\n",
      "2337/2337 - 2s - loss: 0.0121 - accuracy: 0.9961\n",
      "Epoch 91/100\n",
      "2337/2337 - 2s - loss: 0.0120 - accuracy: 0.9961\n",
      "Epoch 92/100\n",
      "2337/2337 - 2s - loss: 0.0120 - accuracy: 0.9965\n",
      "Epoch 93/100\n",
      "2337/2337 - 2s - loss: 0.0116 - accuracy: 0.9966\n",
      "Epoch 94/100\n",
      "2337/2337 - 2s - loss: 0.0115 - accuracy: 0.9966\n",
      "Epoch 95/100\n",
      "2337/2337 - 2s - loss: 0.0119 - accuracy: 0.9963\n",
      "Epoch 96/100\n",
      "2337/2337 - 2s - loss: 0.0117 - accuracy: 0.9960\n",
      "Epoch 97/100\n",
      "2337/2337 - 2s - loss: 0.0115 - accuracy: 0.9964\n",
      "Epoch 98/100\n",
      "2337/2337 - 2s - loss: 0.0120 - accuracy: 0.9966\n",
      "Epoch 99/100\n",
      "2337/2337 - 2s - loss: 0.0116 - accuracy: 0.9965\n",
      "Epoch 100/100\n",
      "2337/2337 - 2s - loss: 0.0113 - accuracy: 0.9967\n",
      "260/260 - 0s - loss: 0.0344 - accuracy: 0.9923\n",
      "Epoch 1/100\n",
      "2337/2337 - 2s - loss: 0.4279 - accuracy: 0.8566\n",
      "Epoch 2/100\n",
      "2337/2337 - 2s - loss: 0.1537 - accuracy: 0.9438\n",
      "Epoch 3/100\n",
      "2337/2337 - 2s - loss: 0.1005 - accuracy: 0.9676\n",
      "Epoch 4/100\n",
      "2337/2337 - 2s - loss: 0.0742 - accuracy: 0.9782\n",
      "Epoch 5/100\n",
      "2337/2337 - 2s - loss: 0.0589 - accuracy: 0.9826\n",
      "Epoch 6/100\n",
      "2337/2337 - 2s - loss: 0.0487 - accuracy: 0.9860\n",
      "Epoch 7/100\n",
      "2337/2337 - 3s - loss: 0.0422 - accuracy: 0.9891\n",
      "Epoch 8/100\n",
      "2337/2337 - 2s - loss: 0.0384 - accuracy: 0.9891\n",
      "Epoch 9/100\n",
      "2337/2337 - 2s - loss: 0.0354 - accuracy: 0.9896\n",
      "Epoch 10/100\n",
      "2337/2337 - 2s - loss: 0.0333 - accuracy: 0.9905\n",
      "Epoch 11/100\n",
      "2337/2337 - 2s - loss: 0.0317 - accuracy: 0.9911\n",
      "Epoch 12/100\n",
      "2337/2337 - 2s - loss: 0.0302 - accuracy: 0.9915\n",
      "Epoch 13/100\n",
      "2337/2337 - 2s - loss: 0.0293 - accuracy: 0.9911\n",
      "Epoch 14/100\n",
      "2337/2337 - 2s - loss: 0.0281 - accuracy: 0.9916\n",
      "Epoch 15/100\n",
      "2337/2337 - 2s - loss: 0.0275 - accuracy: 0.9913\n",
      "Epoch 16/100\n",
      "2337/2337 - 2s - loss: 0.0262 - accuracy: 0.9926\n",
      "Epoch 17/100\n",
      "2337/2337 - 2s - loss: 0.0259 - accuracy: 0.9921\n",
      "Epoch 18/100\n",
      "2337/2337 - 2s - loss: 0.0255 - accuracy: 0.9920\n",
      "Epoch 19/100\n",
      "2337/2337 - 2s - loss: 0.0246 - accuracy: 0.9932\n",
      "Epoch 20/100\n",
      "2337/2337 - 2s - loss: 0.0245 - accuracy: 0.9929\n",
      "Epoch 21/100\n",
      "2337/2337 - 2s - loss: 0.0239 - accuracy: 0.9927\n",
      "Epoch 22/100\n",
      "2337/2337 - 2s - loss: 0.0234 - accuracy: 0.9932\n",
      "Epoch 23/100\n",
      "2337/2337 - 2s - loss: 0.0231 - accuracy: 0.9933\n",
      "Epoch 24/100\n",
      "2337/2337 - 2s - loss: 0.0224 - accuracy: 0.9932\n",
      "Epoch 25/100\n",
      "2337/2337 - 2s - loss: 0.0223 - accuracy: 0.9932\n",
      "Epoch 26/100\n",
      "2337/2337 - 2s - loss: 0.0215 - accuracy: 0.9942\n",
      "Epoch 27/100\n",
      "2337/2337 - 2s - loss: 0.0216 - accuracy: 0.9938\n",
      "Epoch 28/100\n",
      "2337/2337 - 2s - loss: 0.0210 - accuracy: 0.9942\n",
      "Epoch 29/100\n",
      "2337/2337 - 2s - loss: 0.0209 - accuracy: 0.9940\n",
      "Epoch 30/100\n",
      "2337/2337 - 2s - loss: 0.0203 - accuracy: 0.9945\n",
      "Epoch 31/100\n",
      "2337/2337 - 2s - loss: 0.0202 - accuracy: 0.9938\n",
      "Epoch 32/100\n",
      "2337/2337 - 3s - loss: 0.0202 - accuracy: 0.9944\n",
      "Epoch 33/100\n",
      "2337/2337 - 2s - loss: 0.0201 - accuracy: 0.9945\n",
      "Epoch 34/100\n",
      "2337/2337 - 2s - loss: 0.0194 - accuracy: 0.9942\n",
      "Epoch 35/100\n",
      "2337/2337 - 2s - loss: 0.0192 - accuracy: 0.9946\n",
      "Epoch 36/100\n",
      "2337/2337 - 2s - loss: 0.0190 - accuracy: 0.9945\n",
      "Epoch 37/100\n",
      "2337/2337 - 2s - loss: 0.0189 - accuracy: 0.9943\n",
      "Epoch 38/100\n",
      "2337/2337 - 2s - loss: 0.0188 - accuracy: 0.9946\n",
      "Epoch 39/100\n",
      "2337/2337 - 2s - loss: 0.0183 - accuracy: 0.9945\n",
      "Epoch 40/100\n",
      "2337/2337 - 3s - loss: 0.0184 - accuracy: 0.9949\n",
      "Epoch 41/100\n",
      "2337/2337 - 2s - loss: 0.0178 - accuracy: 0.9949\n",
      "Epoch 42/100\n",
      "2337/2337 - 2s - loss: 0.0179 - accuracy: 0.9950\n",
      "Epoch 43/100\n",
      "2337/2337 - 2s - loss: 0.0176 - accuracy: 0.9948\n",
      "Epoch 44/100\n",
      "2337/2337 - 2s - loss: 0.0173 - accuracy: 0.9946\n",
      "Epoch 45/100\n",
      "2337/2337 - 2s - loss: 0.0175 - accuracy: 0.9949\n",
      "Epoch 46/100\n",
      "2337/2337 - 2s - loss: 0.0171 - accuracy: 0.9952\n",
      "Epoch 47/100\n",
      "2337/2337 - 2s - loss: 0.0166 - accuracy: 0.9955\n",
      "Epoch 48/100\n",
      "2337/2337 - 3s - loss: 0.0168 - accuracy: 0.9951\n",
      "Epoch 49/100\n",
      "2337/2337 - 2s - loss: 0.0165 - accuracy: 0.9950\n",
      "Epoch 50/100\n",
      "2337/2337 - 2s - loss: 0.0164 - accuracy: 0.9955\n",
      "Epoch 51/100\n",
      "2337/2337 - 2s - loss: 0.0159 - accuracy: 0.9949\n",
      "Epoch 52/100\n",
      "2337/2337 - 2s - loss: 0.0162 - accuracy: 0.9955\n",
      "Epoch 53/100\n",
      "2337/2337 - 2s - loss: 0.0159 - accuracy: 0.9949\n",
      "Epoch 54/100\n",
      "2337/2337 - 2s - loss: 0.0159 - accuracy: 0.9957\n",
      "Epoch 55/100\n",
      "2337/2337 - 2s - loss: 0.0156 - accuracy: 0.9953\n",
      "Epoch 56/100\n",
      "2337/2337 - 2s - loss: 0.0154 - accuracy: 0.9953\n",
      "Epoch 57/100\n",
      "2337/2337 - 2s - loss: 0.0152 - accuracy: 0.9955\n",
      "Epoch 58/100\n",
      "2337/2337 - 2s - loss: 0.0151 - accuracy: 0.9957\n",
      "Epoch 59/100\n",
      "2337/2337 - 2s - loss: 0.0148 - accuracy: 0.9958\n",
      "Epoch 60/100\n",
      "2337/2337 - 2s - loss: 0.0149 - accuracy: 0.9955\n",
      "Epoch 61/100\n",
      "2337/2337 - 2s - loss: 0.0149 - accuracy: 0.9961\n",
      "Epoch 62/100\n",
      "2337/2337 - 2s - loss: 0.0147 - accuracy: 0.9957\n",
      "Epoch 63/100\n",
      "2337/2337 - 2s - loss: 0.0147 - accuracy: 0.9958\n",
      "Epoch 64/100\n",
      "2337/2337 - 2s - loss: 0.0146 - accuracy: 0.9957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "2337/2337 - 2s - loss: 0.0145 - accuracy: 0.9959\n",
      "Epoch 66/100\n",
      "2337/2337 - 2s - loss: 0.0144 - accuracy: 0.9961\n",
      "Epoch 67/100\n",
      "2337/2337 - 2s - loss: 0.0142 - accuracy: 0.9961\n",
      "Epoch 68/100\n",
      "2337/2337 - 2s - loss: 0.0137 - accuracy: 0.9965\n",
      "Epoch 69/100\n",
      "2337/2337 - 2s - loss: 0.0137 - accuracy: 0.9961\n",
      "Epoch 70/100\n",
      "2337/2337 - 2s - loss: 0.0139 - accuracy: 0.9960\n",
      "Epoch 71/100\n",
      "2337/2337 - 2s - loss: 0.0137 - accuracy: 0.9961\n",
      "Epoch 72/100\n",
      "2337/2337 - 2s - loss: 0.0136 - accuracy: 0.9958\n",
      "Epoch 73/100\n",
      "2337/2337 - 2s - loss: 0.0133 - accuracy: 0.9963\n",
      "Epoch 74/100\n",
      "2337/2337 - 2s - loss: 0.0135 - accuracy: 0.9957\n",
      "Epoch 75/100\n",
      "2337/2337 - 2s - loss: 0.0134 - accuracy: 0.9960\n",
      "Epoch 76/100\n",
      "2337/2337 - 2s - loss: 0.0130 - accuracy: 0.9962\n",
      "Epoch 77/100\n",
      "2337/2337 - 2s - loss: 0.0132 - accuracy: 0.9963\n",
      "Epoch 78/100\n",
      "2337/2337 - 2s - loss: 0.0130 - accuracy: 0.9961\n",
      "Epoch 79/100\n",
      "2337/2337 - 2s - loss: 0.0128 - accuracy: 0.9964\n",
      "Epoch 80/100\n",
      "2337/2337 - 2s - loss: 0.0130 - accuracy: 0.9962\n",
      "Epoch 81/100\n",
      "2337/2337 - 2s - loss: 0.0130 - accuracy: 0.9963\n",
      "Epoch 82/100\n",
      "2337/2337 - 2s - loss: 0.0128 - accuracy: 0.9962\n",
      "Epoch 83/100\n",
      "2337/2337 - 2s - loss: 0.0124 - accuracy: 0.9966\n",
      "Epoch 84/100\n",
      "2337/2337 - 2s - loss: 0.0122 - accuracy: 0.9961\n",
      "Epoch 85/100\n",
      "2337/2337 - 2s - loss: 0.0123 - accuracy: 0.9965\n",
      "Epoch 86/100\n",
      "2337/2337 - 2s - loss: 0.0124 - accuracy: 0.9967\n",
      "Epoch 87/100\n",
      "2337/2337 - 2s - loss: 0.0124 - accuracy: 0.9962\n",
      "Epoch 88/100\n",
      "2337/2337 - 3s - loss: 0.0120 - accuracy: 0.9964\n",
      "Epoch 89/100\n",
      "2337/2337 - 3s - loss: 0.0121 - accuracy: 0.9963\n",
      "Epoch 90/100\n",
      "2337/2337 - 2s - loss: 0.0120 - accuracy: 0.9960\n",
      "Epoch 91/100\n",
      "2337/2337 - 2s - loss: 0.0119 - accuracy: 0.9967\n",
      "Epoch 92/100\n",
      "2337/2337 - 2s - loss: 0.0119 - accuracy: 0.9968\n",
      "Epoch 93/100\n",
      "2337/2337 - 2s - loss: 0.0113 - accuracy: 0.9970\n",
      "Epoch 94/100\n",
      "2337/2337 - 2s - loss: 0.0118 - accuracy: 0.9967\n",
      "Epoch 95/100\n",
      "2337/2337 - 2s - loss: 0.0118 - accuracy: 0.9968\n",
      "Epoch 96/100\n",
      "2337/2337 - 2s - loss: 0.0115 - accuracy: 0.9967\n",
      "Epoch 97/100\n",
      "2337/2337 - 2s - loss: 0.0115 - accuracy: 0.9968\n",
      "Epoch 98/100\n",
      "2337/2337 - 3s - loss: 0.0115 - accuracy: 0.9964\n",
      "Epoch 99/100\n",
      "2337/2337 - 2s - loss: 0.0115 - accuracy: 0.9964\n",
      "Epoch 100/100\n",
      "2337/2337 - 3s - loss: 0.0115 - accuracy: 0.9970\n",
      "260/260 - 0s - loss: 0.0267 - accuracy: 0.9923\n",
      "Epoch 1/100\n",
      "2337/2337 - 3s - loss: 0.4039 - accuracy: 0.8572\n",
      "Epoch 2/100\n",
      "2337/2337 - 2s - loss: 0.1323 - accuracy: 0.9573\n",
      "Epoch 3/100\n",
      "2337/2337 - 2s - loss: 0.0832 - accuracy: 0.9748\n",
      "Epoch 4/100\n",
      "2337/2337 - 3s - loss: 0.0596 - accuracy: 0.9825\n",
      "Epoch 5/100\n",
      "2337/2337 - 2s - loss: 0.0477 - accuracy: 0.9871\n",
      "Epoch 6/100\n",
      "2337/2337 - 3s - loss: 0.0410 - accuracy: 0.9886\n",
      "Epoch 7/100\n",
      "2337/2337 - 3s - loss: 0.0370 - accuracy: 0.9884\n",
      "Epoch 8/100\n",
      "2337/2337 - 2s - loss: 0.0342 - accuracy: 0.9898\n",
      "Epoch 9/100\n",
      "2337/2337 - 2s - loss: 0.0325 - accuracy: 0.9900\n",
      "Epoch 10/100\n",
      "2337/2337 - 2s - loss: 0.0309 - accuracy: 0.9898\n",
      "Epoch 11/100\n",
      "2337/2337 - 2s - loss: 0.0297 - accuracy: 0.9904\n",
      "Epoch 12/100\n",
      "2337/2337 - 2s - loss: 0.0283 - accuracy: 0.9909\n",
      "Epoch 13/100\n",
      "2337/2337 - 2s - loss: 0.0275 - accuracy: 0.9914\n",
      "Epoch 14/100\n",
      "2337/2337 - 2s - loss: 0.0267 - accuracy: 0.9919\n",
      "Epoch 15/100\n",
      "2337/2337 - 2s - loss: 0.0261 - accuracy: 0.9918\n",
      "Epoch 16/100\n",
      "2337/2337 - 2s - loss: 0.0252 - accuracy: 0.9926\n",
      "Epoch 17/100\n",
      "2337/2337 - 2s - loss: 0.0248 - accuracy: 0.9920\n",
      "Epoch 18/100\n",
      "2337/2337 - 2s - loss: 0.0240 - accuracy: 0.9929\n",
      "Epoch 19/100\n",
      "2337/2337 - 2s - loss: 0.0239 - accuracy: 0.9925\n",
      "Epoch 20/100\n",
      "2337/2337 - 2s - loss: 0.0234 - accuracy: 0.9927\n",
      "Epoch 21/100\n",
      "2337/2337 - 2s - loss: 0.0230 - accuracy: 0.9932\n",
      "Epoch 22/100\n",
      "2337/2337 - 2s - loss: 0.0222 - accuracy: 0.9930\n",
      "Epoch 23/100\n",
      "2337/2337 - 2s - loss: 0.0222 - accuracy: 0.9938\n",
      "Epoch 24/100\n",
      "2337/2337 - 2s - loss: 0.0217 - accuracy: 0.9931\n",
      "Epoch 25/100\n",
      "2337/2337 - 3s - loss: 0.0212 - accuracy: 0.9941\n",
      "Epoch 26/100\n",
      "2337/2337 - 2s - loss: 0.0208 - accuracy: 0.9943\n",
      "Epoch 27/100\n",
      "2337/2337 - 2s - loss: 0.0207 - accuracy: 0.9935\n",
      "Epoch 28/100\n",
      "2337/2337 - 2s - loss: 0.0205 - accuracy: 0.9935\n",
      "Epoch 29/100\n",
      "2337/2337 - 2s - loss: 0.0201 - accuracy: 0.9943\n",
      "Epoch 30/100\n",
      "2337/2337 - 2s - loss: 0.0199 - accuracy: 0.9943\n",
      "Epoch 31/100\n",
      "2337/2337 - 2s - loss: 0.0198 - accuracy: 0.9945\n",
      "Epoch 32/100\n",
      "2337/2337 - 2s - loss: 0.0192 - accuracy: 0.9946\n",
      "Epoch 33/100\n",
      "2337/2337 - 2s - loss: 0.0189 - accuracy: 0.9945\n",
      "Epoch 34/100\n",
      "2337/2337 - 2s - loss: 0.0188 - accuracy: 0.9949\n",
      "Epoch 35/100\n",
      "2337/2337 - 3s - loss: 0.0189 - accuracy: 0.9943\n",
      "Epoch 36/100\n",
      "2337/2337 - 2s - loss: 0.0183 - accuracy: 0.9945\n",
      "Epoch 37/100\n",
      "2337/2337 - 2s - loss: 0.0185 - accuracy: 0.9947\n",
      "Epoch 38/100\n",
      "2337/2337 - 2s - loss: 0.0180 - accuracy: 0.9952\n",
      "Epoch 39/100\n",
      "2337/2337 - 2s - loss: 0.0177 - accuracy: 0.9950\n",
      "Epoch 40/100\n",
      "2337/2337 - 2s - loss: 0.0179 - accuracy: 0.9949\n",
      "Epoch 41/100\n",
      "2337/2337 - 2s - loss: 0.0177 - accuracy: 0.9945\n",
      "Epoch 42/100\n",
      "2337/2337 - 2s - loss: 0.0174 - accuracy: 0.9946\n",
      "Epoch 43/100\n",
      "2337/2337 - 2s - loss: 0.0174 - accuracy: 0.9950\n",
      "Epoch 44/100\n",
      "2337/2337 - 3s - loss: 0.0172 - accuracy: 0.9957\n",
      "Epoch 45/100\n",
      "2337/2337 - 3s - loss: 0.0169 - accuracy: 0.9955\n",
      "Epoch 46/100\n",
      "2337/2337 - 3s - loss: 0.0169 - accuracy: 0.9955\n",
      "Epoch 47/100\n",
      "2337/2337 - 3s - loss: 0.0165 - accuracy: 0.9955\n",
      "Epoch 48/100\n",
      "2337/2337 - 3s - loss: 0.0162 - accuracy: 0.9955\n",
      "Epoch 49/100\n",
      "2337/2337 - 3s - loss: 0.0162 - accuracy: 0.9954\n",
      "Epoch 50/100\n",
      "2337/2337 - 3s - loss: 0.0162 - accuracy: 0.9957\n",
      "Epoch 51/100\n",
      "2337/2337 - 2s - loss: 0.0160 - accuracy: 0.9955\n",
      "Epoch 52/100\n",
      "2337/2337 - 2s - loss: 0.0158 - accuracy: 0.9957\n",
      "Epoch 53/100\n",
      "2337/2337 - 3s - loss: 0.0157 - accuracy: 0.9961\n",
      "Epoch 54/100\n",
      "2337/2337 - 3s - loss: 0.0153 - accuracy: 0.9957\n",
      "Epoch 55/100\n",
      "2337/2337 - 3s - loss: 0.0157 - accuracy: 0.9957\n",
      "Epoch 56/100\n",
      "2337/2337 - 3s - loss: 0.0159 - accuracy: 0.9954\n",
      "Epoch 57/100\n",
      "2337/2337 - 3s - loss: 0.0155 - accuracy: 0.9957\n",
      "Epoch 58/100\n",
      "2337/2337 - 3s - loss: 0.0152 - accuracy: 0.9956\n",
      "Epoch 59/100\n",
      "2337/2337 - 3s - loss: 0.0152 - accuracy: 0.9951\n",
      "Epoch 60/100\n",
      "2337/2337 - 3s - loss: 0.0149 - accuracy: 0.9956\n",
      "Epoch 61/100\n",
      "2337/2337 - 2s - loss: 0.0146 - accuracy: 0.9959\n",
      "Epoch 62/100\n",
      "2337/2337 - 2s - loss: 0.0148 - accuracy: 0.9955\n",
      "Epoch 63/100\n",
      "2337/2337 - 2s - loss: 0.0143 - accuracy: 0.9962\n",
      "Epoch 64/100\n",
      "2337/2337 - 2s - loss: 0.0145 - accuracy: 0.9959\n",
      "Epoch 65/100\n",
      "2337/2337 - 3s - loss: 0.0147 - accuracy: 0.9958\n",
      "Epoch 66/100\n",
      "2337/2337 - 3s - loss: 0.0146 - accuracy: 0.9958\n",
      "Epoch 67/100\n",
      "2337/2337 - 4s - loss: 0.0141 - accuracy: 0.9960\n",
      "Epoch 68/100\n",
      "2337/2337 - 3s - loss: 0.0144 - accuracy: 0.9961\n",
      "Epoch 69/100\n",
      "2337/2337 - 3s - loss: 0.0138 - accuracy: 0.9958\n",
      "Epoch 70/100\n",
      "2337/2337 - 3s - loss: 0.0142 - accuracy: 0.9959\n",
      "Epoch 71/100\n",
      "2337/2337 - 3s - loss: 0.0140 - accuracy: 0.9961\n",
      "Epoch 72/100\n",
      "2337/2337 - 2s - loss: 0.0142 - accuracy: 0.9960\n",
      "Epoch 73/100\n",
      "2337/2337 - 3s - loss: 0.0139 - accuracy: 0.9959\n",
      "Epoch 74/100\n",
      "2337/2337 - 3s - loss: 0.0135 - accuracy: 0.9960\n",
      "Epoch 75/100\n",
      "2337/2337 - 3s - loss: 0.0137 - accuracy: 0.9963\n",
      "Epoch 76/100\n",
      "2337/2337 - 2s - loss: 0.0140 - accuracy: 0.9959\n",
      "Epoch 77/100\n",
      "2337/2337 - 3s - loss: 0.0135 - accuracy: 0.9962\n",
      "Epoch 78/100\n",
      "2337/2337 - 3s - loss: 0.0134 - accuracy: 0.9967\n",
      "Epoch 79/100\n",
      "2337/2337 - 3s - loss: 0.0133 - accuracy: 0.9966\n",
      "Epoch 80/100\n",
      "2337/2337 - 3s - loss: 0.0130 - accuracy: 0.9959\n",
      "Epoch 81/100\n",
      "2337/2337 - 2s - loss: 0.0135 - accuracy: 0.9962\n",
      "Epoch 82/100\n",
      "2337/2337 - 2s - loss: 0.0129 - accuracy: 0.9964\n",
      "Epoch 83/100\n",
      "2337/2337 - 2s - loss: 0.0132 - accuracy: 0.9964\n",
      "Epoch 84/100\n",
      "2337/2337 - 2s - loss: 0.0132 - accuracy: 0.9965\n",
      "Epoch 85/100\n",
      "2337/2337 - 2s - loss: 0.0130 - accuracy: 0.9962\n",
      "Epoch 86/100\n",
      "2337/2337 - 2s - loss: 0.0129 - accuracy: 0.9963\n",
      "Epoch 87/100\n",
      "2337/2337 - 2s - loss: 0.0127 - accuracy: 0.9964\n",
      "Epoch 88/100\n",
      "2337/2337 - 2s - loss: 0.0130 - accuracy: 0.9964\n",
      "Epoch 89/100\n",
      "2337/2337 - 2s - loss: 0.0128 - accuracy: 0.9967\n",
      "Epoch 90/100\n",
      "2337/2337 - 2s - loss: 0.0129 - accuracy: 0.9964\n",
      "Epoch 91/100\n",
      "2337/2337 - 2s - loss: 0.0127 - accuracy: 0.9962\n",
      "Epoch 92/100\n",
      "2337/2337 - 2s - loss: 0.0127 - accuracy: 0.9959\n",
      "Epoch 93/100\n",
      "2337/2337 - 2s - loss: 0.0125 - accuracy: 0.9964\n",
      "Epoch 94/100\n",
      "2337/2337 - 2s - loss: 0.0127 - accuracy: 0.9961\n",
      "Epoch 95/100\n",
      "2337/2337 - 2s - loss: 0.0124 - accuracy: 0.9962\n",
      "Epoch 96/100\n",
      "2337/2337 - 2s - loss: 0.0122 - accuracy: 0.9965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "2337/2337 - 2s - loss: 0.0126 - accuracy: 0.9959\n",
      "Epoch 98/100\n",
      "2337/2337 - 2s - loss: 0.0123 - accuracy: 0.9961\n",
      "Epoch 99/100\n",
      "2337/2337 - 2s - loss: 0.0123 - accuracy: 0.9966\n",
      "Epoch 100/100\n",
      "2337/2337 - 2s - loss: 0.0121 - accuracy: 0.9965\n",
      "260/260 - 0s - loss: 0.0203 - accuracy: 0.9969\n",
      "Epoch 1/100\n",
      "2337/2337 - 2s - loss: 0.3670 - accuracy: 0.8783\n",
      "Epoch 2/100\n",
      "2337/2337 - 2s - loss: 0.1274 - accuracy: 0.9588\n",
      "Epoch 3/100\n",
      "2337/2337 - 2s - loss: 0.0812 - accuracy: 0.9759\n",
      "Epoch 4/100\n",
      "2337/2337 - 2s - loss: 0.0605 - accuracy: 0.9813\n",
      "Epoch 5/100\n",
      "2337/2337 - 3s - loss: 0.0490 - accuracy: 0.9852\n",
      "Epoch 6/100\n",
      "2337/2337 - 2s - loss: 0.0421 - accuracy: 0.9875\n",
      "Epoch 7/100\n",
      "2337/2337 - 2s - loss: 0.0382 - accuracy: 0.9880\n",
      "Epoch 8/100\n",
      "2337/2337 - 2s - loss: 0.0353 - accuracy: 0.9895\n",
      "Epoch 9/100\n",
      "2337/2337 - 3s - loss: 0.0333 - accuracy: 0.9900\n",
      "Epoch 10/100\n",
      "2337/2337 - 2s - loss: 0.0316 - accuracy: 0.9897\n",
      "Epoch 11/100\n",
      "2337/2337 - 2s - loss: 0.0298 - accuracy: 0.9909\n",
      "Epoch 12/100\n",
      "2337/2337 - 2s - loss: 0.0289 - accuracy: 0.9909\n",
      "Epoch 13/100\n",
      "2337/2337 - 2s - loss: 0.0282 - accuracy: 0.9911\n",
      "Epoch 14/100\n",
      "2337/2337 - 2s - loss: 0.0274 - accuracy: 0.9919\n",
      "Epoch 15/100\n",
      "2337/2337 - 2s - loss: 0.0268 - accuracy: 0.9920\n",
      "Epoch 16/100\n",
      "2337/2337 - 2s - loss: 0.0258 - accuracy: 0.9918\n",
      "Epoch 17/100\n",
      "2337/2337 - 2s - loss: 0.0254 - accuracy: 0.9922\n",
      "Epoch 18/100\n",
      "2337/2337 - 2s - loss: 0.0247 - accuracy: 0.9926\n",
      "Epoch 19/100\n",
      "2337/2337 - 2s - loss: 0.0240 - accuracy: 0.9931\n",
      "Epoch 20/100\n",
      "2337/2337 - 2s - loss: 0.0238 - accuracy: 0.9932\n",
      "Epoch 21/100\n",
      "2337/2337 - 2s - loss: 0.0234 - accuracy: 0.9937\n",
      "Epoch 22/100\n",
      "2337/2337 - 2s - loss: 0.0228 - accuracy: 0.9932\n",
      "Epoch 23/100\n",
      "2337/2337 - 2s - loss: 0.0226 - accuracy: 0.9932\n",
      "Epoch 24/100\n",
      "2337/2337 - 2s - loss: 0.0220 - accuracy: 0.9935\n",
      "Epoch 25/100\n",
      "2337/2337 - 2s - loss: 0.0216 - accuracy: 0.9938\n",
      "Epoch 26/100\n",
      "2337/2337 - 2s - loss: 0.0211 - accuracy: 0.9938\n",
      "Epoch 27/100\n",
      "2337/2337 - 2s - loss: 0.0209 - accuracy: 0.9940\n",
      "Epoch 28/100\n",
      "2337/2337 - 2s - loss: 0.0209 - accuracy: 0.9944\n",
      "Epoch 29/100\n",
      "2337/2337 - 2s - loss: 0.0208 - accuracy: 0.9947\n",
      "Epoch 30/100\n",
      "2337/2337 - 2s - loss: 0.0200 - accuracy: 0.9945\n",
      "Epoch 31/100\n",
      "2337/2337 - 2s - loss: 0.0200 - accuracy: 0.9946\n",
      "Epoch 32/100\n",
      "2337/2337 - 2s - loss: 0.0194 - accuracy: 0.9942\n",
      "Epoch 33/100\n",
      "2337/2337 - 2s - loss: 0.0192 - accuracy: 0.9943\n",
      "Epoch 34/100\n",
      "2337/2337 - 2s - loss: 0.0189 - accuracy: 0.9946\n",
      "Epoch 35/100\n",
      "2337/2337 - 2s - loss: 0.0189 - accuracy: 0.9944\n",
      "Epoch 36/100\n",
      "2337/2337 - 2s - loss: 0.0187 - accuracy: 0.9945\n",
      "Epoch 37/100\n",
      "2337/2337 - 2s - loss: 0.0186 - accuracy: 0.9946\n",
      "Epoch 38/100\n",
      "2337/2337 - 2s - loss: 0.0179 - accuracy: 0.9946\n",
      "Epoch 39/100\n",
      "2337/2337 - 2s - loss: 0.0179 - accuracy: 0.9953\n",
      "Epoch 40/100\n",
      "2337/2337 - 2s - loss: 0.0177 - accuracy: 0.9953\n",
      "Epoch 41/100\n",
      "2337/2337 - 2s - loss: 0.0177 - accuracy: 0.9949\n",
      "Epoch 42/100\n",
      "2337/2337 - 2s - loss: 0.0174 - accuracy: 0.9952\n",
      "Epoch 43/100\n",
      "2337/2337 - 2s - loss: 0.0170 - accuracy: 0.9955\n",
      "Epoch 44/100\n",
      "2337/2337 - 2s - loss: 0.0169 - accuracy: 0.9952\n",
      "Epoch 45/100\n",
      "2337/2337 - 2s - loss: 0.0168 - accuracy: 0.9953\n",
      "Epoch 46/100\n",
      "2337/2337 - 2s - loss: 0.0166 - accuracy: 0.9955\n",
      "Epoch 47/100\n",
      "2337/2337 - 2s - loss: 0.0163 - accuracy: 0.9961\n",
      "Epoch 48/100\n",
      "2337/2337 - 2s - loss: 0.0164 - accuracy: 0.9953\n",
      "Epoch 49/100\n",
      "2337/2337 - 2s - loss: 0.0160 - accuracy: 0.9954\n",
      "Epoch 50/100\n",
      "2337/2337 - 2s - loss: 0.0161 - accuracy: 0.9955\n",
      "Epoch 51/100\n",
      "2337/2337 - 2s - loss: 0.0161 - accuracy: 0.9957\n",
      "Epoch 52/100\n",
      "2337/2337 - 2s - loss: 0.0160 - accuracy: 0.9954\n",
      "Epoch 53/100\n",
      "2337/2337 - 2s - loss: 0.0158 - accuracy: 0.9956\n",
      "Epoch 54/100\n",
      "2337/2337 - 2s - loss: 0.0155 - accuracy: 0.9957\n",
      "Epoch 55/100\n",
      "2337/2337 - 2s - loss: 0.0152 - accuracy: 0.9961\n",
      "Epoch 56/100\n",
      "2337/2337 - 2s - loss: 0.0152 - accuracy: 0.9961\n",
      "Epoch 57/100\n",
      "2337/2337 - 2s - loss: 0.0152 - accuracy: 0.9959\n",
      "Epoch 58/100\n",
      "2337/2337 - 2s - loss: 0.0150 - accuracy: 0.9959\n",
      "Epoch 59/100\n",
      "2337/2337 - 2s - loss: 0.0148 - accuracy: 0.9958\n",
      "Epoch 60/100\n",
      "2337/2337 - 2s - loss: 0.0147 - accuracy: 0.9961\n",
      "Epoch 61/100\n",
      "2337/2337 - 2s - loss: 0.0147 - accuracy: 0.9959\n",
      "Epoch 62/100\n",
      "2337/2337 - 2s - loss: 0.0145 - accuracy: 0.9960\n",
      "Epoch 63/100\n",
      "2337/2337 - 2s - loss: 0.0145 - accuracy: 0.9965\n",
      "Epoch 64/100\n",
      "2337/2337 - 2s - loss: 0.0143 - accuracy: 0.9964\n",
      "Epoch 65/100\n",
      "2337/2337 - 2s - loss: 0.0142 - accuracy: 0.9965\n",
      "Epoch 66/100\n",
      "2337/2337 - 2s - loss: 0.0139 - accuracy: 0.9963\n",
      "Epoch 67/100\n",
      "2337/2337 - 2s - loss: 0.0139 - accuracy: 0.9965\n",
      "Epoch 68/100\n",
      "2337/2337 - 2s - loss: 0.0139 - accuracy: 0.9967\n",
      "Epoch 69/100\n",
      "2337/2337 - 2s - loss: 0.0138 - accuracy: 0.9961\n",
      "Epoch 70/100\n",
      "2337/2337 - 2s - loss: 0.0137 - accuracy: 0.9964\n",
      "Epoch 71/100\n",
      "2337/2337 - 2s - loss: 0.0139 - accuracy: 0.9968\n",
      "Epoch 72/100\n",
      "2337/2337 - 2s - loss: 0.0136 - accuracy: 0.9966\n",
      "Epoch 73/100\n",
      "2337/2337 - 2s - loss: 0.0132 - accuracy: 0.9964\n",
      "Epoch 74/100\n",
      "2337/2337 - 2s - loss: 0.0129 - accuracy: 0.9966\n",
      "Epoch 75/100\n",
      "2337/2337 - 2s - loss: 0.0135 - accuracy: 0.9962\n",
      "Epoch 76/100\n",
      "2337/2337 - 2s - loss: 0.0131 - accuracy: 0.9967\n",
      "Epoch 77/100\n",
      "2337/2337 - 2s - loss: 0.0129 - accuracy: 0.9963\n",
      "Epoch 78/100\n",
      "2337/2337 - 2s - loss: 0.0129 - accuracy: 0.9965\n",
      "Epoch 79/100\n",
      "2337/2337 - 2s - loss: 0.0131 - accuracy: 0.9967\n",
      "Epoch 80/100\n",
      "2337/2337 - 2s - loss: 0.0127 - accuracy: 0.9967\n",
      "Epoch 81/100\n",
      "2337/2337 - 2s - loss: 0.0128 - accuracy: 0.9965\n",
      "Epoch 82/100\n",
      "2337/2337 - 2s - loss: 0.0129 - accuracy: 0.9963\n",
      "Epoch 83/100\n",
      "2337/2337 - 2s - loss: 0.0123 - accuracy: 0.9967\n",
      "Epoch 84/100\n",
      "2337/2337 - 2s - loss: 0.0126 - accuracy: 0.9965\n",
      "Epoch 85/100\n",
      "2337/2337 - 2s - loss: 0.0124 - accuracy: 0.9963\n",
      "Epoch 86/100\n",
      "2337/2337 - 2s - loss: 0.0123 - accuracy: 0.9967\n",
      "Epoch 87/100\n",
      "2337/2337 - 2s - loss: 0.0121 - accuracy: 0.9967\n",
      "Epoch 88/100\n",
      "2337/2337 - 2s - loss: 0.0125 - accuracy: 0.9966\n",
      "Epoch 89/100\n",
      "2337/2337 - 2s - loss: 0.0124 - accuracy: 0.9968\n",
      "Epoch 90/100\n",
      "2337/2337 - 2s - loss: 0.0121 - accuracy: 0.9965\n",
      "Epoch 91/100\n",
      "2337/2337 - 2s - loss: 0.0120 - accuracy: 0.9966\n",
      "Epoch 92/100\n",
      "2337/2337 - 2s - loss: 0.0120 - accuracy: 0.9969\n",
      "Epoch 93/100\n",
      "2337/2337 - 2s - loss: 0.0118 - accuracy: 0.9966\n",
      "Epoch 94/100\n",
      "2337/2337 - 2s - loss: 0.0119 - accuracy: 0.9966\n",
      "Epoch 95/100\n",
      "2337/2337 - 2s - loss: 0.0120 - accuracy: 0.9967\n",
      "Epoch 96/100\n",
      "2337/2337 - 4s - loss: 0.0116 - accuracy: 0.9964\n",
      "Epoch 97/100\n",
      "2337/2337 - 2s - loss: 0.0117 - accuracy: 0.9971\n",
      "Epoch 98/100\n",
      "2337/2337 - 3s - loss: 0.0117 - accuracy: 0.9968\n",
      "Epoch 99/100\n",
      "2337/2337 - 4s - loss: 0.0115 - accuracy: 0.9968\n",
      "Epoch 100/100\n",
      "2337/2337 - 3s - loss: 0.0116 - accuracy: 0.9967\n",
      "260/260 - 0s - loss: 0.0179 - accuracy: 0.9938\n",
      "Epoch 1/100\n",
      "2337/2337 - 3s - loss: 0.3975 - accuracy: 0.8614\n",
      "Epoch 2/100\n",
      "2337/2337 - 3s - loss: 0.1414 - accuracy: 0.9473\n",
      "Epoch 3/100\n",
      "2337/2337 - 3s - loss: 0.0880 - accuracy: 0.9729\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4e43107227c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Baseline: %.2f%% (%.2f%%)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    402\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    240\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    241\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 242\u001b[0;31m     scores = parallel(\n\u001b[0m\u001b[1;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    244\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
