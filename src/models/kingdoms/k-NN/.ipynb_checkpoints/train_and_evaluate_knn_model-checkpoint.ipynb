{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.utils import np_utils\n",
    "import keras.metrics as metrics\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import combinations \n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import (KNeighborsClassifier,\n",
    "                               NeighborhoodComponentsAnalysis)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arc', 'phg', 'euk', 'vrl', 'bct'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['vrl', 0.01654, 0.012029999999999999, ..., 0.00251, 0.0005, 0.0],\n",
       "       ['vrl', 0.027139999999999997, 0.013569999999999999, ..., 0.00271,\n",
       "        0.0006799999999999999, 0.0],\n",
       "       ['vrl', 0.01974, 0.0218, ..., 0.00391, 0.0, 0.00144],\n",
       "       ...,\n",
       "       ['euk', 0.014230000000000001, 0.03321, ..., 0.0035600000000000002,\n",
       "        0.00119, 0.02017],\n",
       "       ['euk', 0.01757, 0.02028, ..., 0.00099, 0.00079, 0.00156],\n",
       "       ['euk', 0.01778, 0.037239999999999995, ..., 0.00156, 0.00114,\n",
       "        0.02161]], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset \n",
    "\n",
    "full_dataset = pd.read_csv(\"/Users/nickpark/Desktop/codon-data/codon_usage.csv\", low_memory=False)\n",
    "dataset = full_dataset[~full_dataset[\"Kingdom\"].eq('plm')]\n",
    "\n",
    "# Remove irrelevant columns\n",
    "\n",
    "dataset = dataset.drop([\"DNAtype\", \"SpeciesID\", \"Ncodons\", \"SpeciesName\"], axis=1)\n",
    "dataset[\"Kingdom\"] = dataset[\"Kingdom\"].map({\n",
    "    'pln': 'euk',\n",
    "    'inv': 'euk',\n",
    "    'vrt': 'euk',\n",
    "    'mam': 'euk',\n",
    "    'rod': 'euk',\n",
    "    'pri': 'euk',\n",
    "    'bct': 'bct',\n",
    "    'vrl': 'vrl',\n",
    "    'arc': 'arc',\n",
    "    'plm': 'plm',\n",
    "    'phg': 'phg'\n",
    "})\n",
    "\n",
    "print(set(dataset[\"Kingdom\"]))\n",
    "\n",
    "# Remove weird rows\n",
    "\n",
    "cols=[i for i in dataset.columns if i not in [\"Kingdom\"]]\n",
    "for col in cols:\n",
    "    dataset[col] = pd.to_numeric(dataset[col], errors='coerce')\n",
    "# dataset = dataset.apply(pd.to_numeric, errors='coerce')\n",
    "dataset = dataset[~dataset.applymap(pd.isnull).any(1)]\n",
    "dataset = dataset.to_numpy()\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01654 0.01203 0.0005  ... 0.00251 0.0005  0.     ]\n",
      " [0.02714 0.01357 0.00068 ... 0.00271 0.00068 0.     ]\n",
      " [0.01974 0.0218  0.01357 ... 0.00391 0.      0.00144]\n",
      " ...\n",
      " [0.01423 0.03321 0.01661 ... 0.00356 0.00119 0.02017]\n",
      " [0.01757 0.02028 0.00767 ... 0.00099 0.00079 0.00156]\n",
      " [0.01778 0.03724 0.01732 ... 0.00156 0.00114 0.02161]] ['vrl' 'vrl' 'vrl' ... 'euk' 'euk' 'euk']\n"
     ]
    }
   ],
   "source": [
    "X = dataset[:,1:].astype('float')\n",
    "y = dataset[:,0].astype('str')\n",
    "print(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size=0.20, stratify = dummy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "sklearn.metrics.roc_auc_score(y_test, y_pred, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function with 5-fold cross-validation\n",
    "\n",
    "def train_knn(X, y, k=3):\n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    roc_scores = cross_val_score(\n",
    "        classifier,\n",
    "        X, \n",
    "        y, \n",
    "        cv=5, \n",
    "        scoring='roc_auc_ovr', \n",
    "    )\n",
    "    \n",
    "    roc_average = sum(roc_scores)/len(roc_scores)\n",
    "    \n",
    "    f1_micro_scores = cross_val_score(\n",
    "        classifier,\n",
    "        X, \n",
    "        y, \n",
    "        cv=5, \n",
    "        scoring='f1_micro', \n",
    "    )\n",
    "    \n",
    "    f1_micro_average = sum(f1_micro_scores)/len(f1_micro_scores)\n",
    "    \n",
    "    f1_macro_scores = cross_val_score(\n",
    "        classifier,\n",
    "        X, \n",
    "        y, \n",
    "        cv=5, \n",
    "        scoring='f1_macro', \n",
    "    )\n",
    "    \n",
    "    f1_macro_average = sum(f1_macro_scores)/len(f1_macro_scores)\n",
    "    \n",
    "    return roc_average, f1_micro_average, f1_macro_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,1:].astype('float')\n",
    "\n",
    "y = dataset[:,0].astype('str')\n",
    "\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "for k in [1,2,3,4,5]:\n",
    "    roc_average, f1_micro_average, f1_macro_average = train_knn(X, y, k=k)\n",
    "    print('scores for', k, ':', roc_average, f1_micro_average, f1_macro_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using PCA:\n",
    "\n",
    "def train_knn_with_pca(X, y, p=15, random_state=13):\n",
    "\n",
    "    pca = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        PCA(n_components=p, random_state=random_state)\n",
    "    )\n",
    "    \n",
    "    pca.fit(X,y)\n",
    "    \n",
    "    return train_knn(pca.transform(X),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,1:].astype('float')\n",
    "\n",
    "y = dataset[:,0].astype('str')\n",
    "\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_y = encoder.transform(y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_y)\n",
    "\n",
    "for p in range(1,64):\n",
    "    scores = train_knn_with_pca(X, y, p=p)\n",
    "    print('with p pca features, got scores of', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
